{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64e9cfcb",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-10-29T05:21:43.295287Z",
     "iopub.status.busy": "2022-10-29T05:21:43.294330Z",
     "iopub.status.idle": "2022-10-29T05:21:44.499593Z",
     "shell.execute_reply": "2022-10-29T05:21:44.498050Z"
    },
    "papermill": {
     "duration": 1.222605,
     "end_time": "2022-10-29T05:21:44.511048",
     "exception": false,
     "start_time": "2022-10-29T05:21:43.288443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26b5441d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T05:21:44.522152Z",
     "iopub.status.busy": "2022-10-29T05:21:44.520451Z",
     "iopub.status.idle": "2022-10-29T05:21:44.541086Z",
     "shell.execute_reply": "2022-10-29T05:21:44.539985Z"
    },
    "papermill": {
     "duration": 0.028932,
     "end_time": "2022-10-29T05:21:44.544014",
     "exception": false,
     "start_time": "2022-10-29T05:21:44.515082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Data_Handler():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def load_data(self):\n",
    "        path = r\"../input/datasets-for-regression/Bank_Customer_Churn_Prediction/Bank_Customer_Churn_Prediction.csv\"\n",
    "    \n",
    "        df = pd.read_csv(path, header=None, delimiter=\",\")\n",
    "        df = df.drop(0, axis = 1)\n",
    "        features = df.iloc[1:, 0:10]\n",
    "        labels = df.iloc[1:, -1]\n",
    "        return (features, labels)\n",
    "\n",
    "    def one_hot_encode(self, features):\n",
    "        encoded_country = pd.get_dummies(features[2])\n",
    "        encoded_gender = pd.get_dummies(features[3])\n",
    "    \n",
    "        merged_columns = pd.concat([encoded_country, encoded_gender], axis = \"columns\")\n",
    "        features = pd.concat([features, merged_columns], axis = \"columns\")\n",
    "        features = features.drop([2, 3], axis = \"columns\")\n",
    "        return features\n",
    "    \n",
    "    def split_data(self, features, labels):\n",
    "        total_samples = features.shape[0]\n",
    "        feature_columns = features.columns.values.tolist()\n",
    "        test_split_size = int(np.ceil((20 / 100) * total_samples))\n",
    "    \n",
    "        train_x, test_x, train_y, test_y = train_test_split(features, labels, test_size = test_split_size)\n",
    "\n",
    "        train_x = train_x.reset_index(drop = True)\n",
    "        test_x = test_x.reset_index(drop = True)\n",
    "        train_y = train_y.reset_index(drop = True)\n",
    "        test_y = test_y.reset_index(drop = True)\n",
    "    \n",
    "        train_y = train_y.astype(float)\n",
    "        test_y = test_y.astype(float)\n",
    "\n",
    "        for column in feature_columns:\n",
    "            train_x[column] = train_x[column].astype(float)\n",
    "            test_x[column] = test_x[column].astype(float)\n",
    "\n",
    "        return (train_x, test_x, train_y, test_y)\n",
    "    \n",
    "    def min_max_normalization(self, df):\n",
    "        normalized_df = (df - df.min()) / (df.max() - df.min())\n",
    "        return normalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a3955e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T05:21:44.551440Z",
     "iopub.status.busy": "2022-10-29T05:21:44.550998Z",
     "iopub.status.idle": "2022-10-29T05:21:44.557981Z",
     "shell.execute_reply": "2022-10-29T05:21:44.556039Z"
    },
    "papermill": {
     "duration": 0.014265,
     "end_time": "2022-10-29T05:21:44.561067",
     "exception": false,
     "start_time": "2022-10-29T05:21:44.546802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_data(train_costs, test_costs, epochs):\n",
    "    plt.plot(epochs, train_costs, 'g', label = \"Training Cost\")\n",
    "    plt.plot(epochs, test_costs, 'r', label = \"Testing Cost\")\n",
    "    plt.legend()\n",
    "    plt.gca().set_ylim(top = 1)\n",
    "    plt.gca().set_ylim(bottom = 0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc993eee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T05:21:44.569341Z",
     "iopub.status.busy": "2022-10-29T05:21:44.568884Z",
     "iopub.status.idle": "2022-10-29T05:21:44.618560Z",
     "shell.execute_reply": "2022-10-29T05:21:44.616575Z"
    },
    "papermill": {
     "duration": 0.059038,
     "end_time": "2022-10-29T05:21:44.623057",
     "exception": false,
     "start_time": "2022-10-29T05:21:44.564019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Neural_Network():\n",
    "    def __init__(self, epochs, lr, hidden_nodes):\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        \n",
    "        # Getting features and labels\n",
    "        dataset = Data_Handler()\n",
    "        self.features, self.labels = dataset.load_data()\n",
    "        print(f\"Fetures Before One Hot Encoding \\n{self.features}\\n\" + \"-\" * 150, \"\\n\")\n",
    "        print(f\"Labels \\n{self.labels}\\n\" + \"-\" * 150, \"\\n\")\n",
    "        \n",
    "        # Applying One Hot Encoding\n",
    "        self.features = dataset.one_hot_encode(self.features)\n",
    "        print(f\"Fetures After One Hot Encoding \\n{self.features}\\n\" + \"-\" * 150, \"\\n\")\n",
    "        \n",
    "        # Spilitting data into training and testing subsets\n",
    "        self.train_f, self.test_f, self.train_l, self.test_l = dataset.split_data(self.features, self.labels)\n",
    "        print(f\"Training Features \\n{self.train_f}\\n\" + \"-\" * 150, \"\\n\")\n",
    "        print(f\"Testing Features \\n{self.test_f}\\n\" + \"-\" * 150, \"\\n\")\n",
    "        print(f\"Training Labels \\n{self.train_l}\\n\" + \"-\" * 150, \"\\n\")\n",
    "        print(f\"Testing Labels \\n{self.test_l}\\n\" + \"-\" * 150, \"\\n\")\n",
    "        \n",
    "        # Normalizing features\n",
    "        self.train_f = dataset.min_max_normalization(self.train_f)\n",
    "        self.test_f = dataset.min_max_normalization(self.test_f)\n",
    "        print(f\"Training Features After Min-Max Normalization \\n{self.train_f}\\n\" + \"-\" * 150, \"\\n\")\n",
    "        print(f\"Testing Features After Min-Max Normalization \\n{self.test_f}\\n\" + \"-\" * 150, \"\\n\")\n",
    "        \n",
    "        # Initializing weights and biases for both layers\n",
    "        self.weights_layer1, self.weights_layer2, self.biases_layer1, self.biases_layer2 = self.init_parameters(13, self.hidden_nodes, 1)\n",
    "        \n",
    "    def cost_function(self, y, y_hat, total_samples):\n",
    "        y_hat.shape = (total_samples,)\n",
    "        cost = (-1 / total_samples) * np.sum(y * np.log(0.0001 + y_hat) + (1 - y) * np.log(0.0001 + 1 - y_hat))\n",
    "        return cost\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        z = 1 / (1 + np.exp(-z))\n",
    "        return z\n",
    "\n",
    "    def relu(self, z):\n",
    "        return np.maximum(z, 0)\n",
    "    \n",
    "    def init_parameters(self, input_features, hidden_nodes, output_nodes):\n",
    "        num_weights_l1 = input_features * hidden_nodes\n",
    "        num_weights_l2 = hidden_nodes * output_nodes\n",
    "        num_biases_l1 = hidden_nodes\n",
    "        num_biases_l2 = output_nodes\n",
    "        \n",
    "        # Matrix of hidden_nodes * input\n",
    "        weights_layer1 = []\n",
    "        # Matrix of 1 * hidden_nodes\n",
    "        weights_layer2 = []\n",
    "        # Matrix of hidden_units * 1\n",
    "        biases_layer1 = []\n",
    "        # Matrix of 1 * 1\n",
    "        biases_layer2 = []\n",
    "        \n",
    "        for _ in range(hidden_nodes):\n",
    "            temp = []\n",
    "            for _ in range(input_features):\n",
    "                temp.append(round(random.uniform(-0.5, 0.5), 1))\n",
    "                \n",
    "            weights_layer1.append(np.array(temp))\n",
    "        \n",
    "        for _ in range(1):\n",
    "            temp = []\n",
    "            for _ in range(hidden_nodes):\n",
    "                temp.append(round(random.uniform(-0.5, 0.5), 1))\n",
    "            \n",
    "            weights_layer2.append(np.array(temp))\n",
    "            \n",
    "        for _ in range(hidden_nodes):\n",
    "            temp = []\n",
    "            for _ in range(1):\n",
    "                temp.append(round(random.uniform(-0.5, 0.5), 1))\n",
    "                \n",
    "            biases_layer1.append(np.array(temp))\n",
    "            \n",
    "        for _ in range(1):\n",
    "            temp = []\n",
    "            for _ in range(1):\n",
    "                temp.append(round(random.uniform(-0.5, 0.5), 1))\n",
    "                \n",
    "            biases_layer2.append(np.array(temp))\n",
    "        \n",
    "        return (np.array(weights_layer1), np.array(weights_layer2), np.array(biases_layer1), np.array(biases_layer2))    \n",
    "    \n",
    "    def forward_pass(self, input_features, weights_layer1, weights_layer2, biases_layer1, biases_layer2):\n",
    "        # Weighted sum for layer 1\n",
    "        weighted_sums_layer1 = np.dot(weights_layer1, input_features.T)\n",
    "        weighted_sums_layer1 = np.add(weighted_sums_layer1, biases_layer1)\n",
    "        \n",
    "        # Applying Relu\n",
    "        for index in range(self.hidden_nodes):\n",
    "            weighted_sums_layer1[index] = self.relu(weighted_sums_layer1[index])\n",
    "        \n",
    "        # Weighted sum for layer 2\n",
    "        weighted_sums_layer2 = np.dot(weights_layer2, weighted_sums_layer1)\n",
    "        weighted_sums_layer2 = np.add(weighted_sums_layer2, biases_layer2)\n",
    "        \n",
    "        # Applying Sigmoid\n",
    "        y_hat = self.sigmoid(weighted_sums_layer2)\n",
    "        return y_hat, weighted_sums_layer1\n",
    "    \n",
    "    def backward_pass(self, y_hat, weighted_sums_layer1):\n",
    "        # Calculate gradient of output node\n",
    "        error_O = y_hat * (1 - y_hat) * (self.train_l - y_hat)\n",
    "        error_O = np.mean(error_O)\n",
    "        \n",
    "        # Calculate gradient of hidden nodes\n",
    "        t1 = np.dot(error_O, self.weights_layer2)\n",
    "        t2 = 1 - weighted_sums_layer1\n",
    "        t3 = np.dot(weighted_sums_layer1, t2.T)\n",
    "        errors_H = np.dot(t1, t3)\n",
    "        \n",
    "        # Calculating new parameters for layer 2\n",
    "        weights_layer2 = self.weights_layer2 + np.mean(np.dot(self.lr, np.dot(error_O, weighted_sums_layer1)))\n",
    "        biases_layer2 = self.biases_layer2 + np.dot(self.lr, error_O)\n",
    "        \n",
    "        # Calculating new parameters for layer 1\n",
    "        means_of_feature_inputs = np.mean(self.train_f.T, axis = 1)\n",
    "        means_of_feature_inputs = np.array(means_of_feature_inputs.tolist())\n",
    "        means_of_feature_inputs.shape = (1, 13)\n",
    "        weights_layer1 = self.weights_layer1 + np.mean(np.dot(self.lr, np.dot(errors_H.T, means_of_feature_inputs)))\n",
    "        biases_layer1 = self.biases_layer1 + np.dot(self.lr, errors_H.T)\n",
    "        \n",
    "        return (weights_layer1, weights_layer2, biases_layer1, biases_layer2)\n",
    "    \n",
    "    def fit(self):\n",
    "        train_costs = []\n",
    "        test_costs = []\n",
    "        epochs_list = []\n",
    "        training_cost = 0\n",
    "        testing_cost = 0\n",
    "        total_train_samples = self.train_f.shape[0]\n",
    "        total_test_samples = self.test_f.shape[0]\n",
    "        \n",
    "        for epoch in tqdm(range(self.epochs + 1), desc = \"Progress\"):\n",
    "            y_hat, weighted_sums_layer1 = self.forward_pass(self.train_f, self.weights_layer1, self.weights_layer2, self.biases_layer1, self.biases_layer2)\n",
    "            y_pred, _ = self.forward_pass(self.test_f, self.weights_layer1, self.weights_layer2, self.biases_layer1, self.biases_layer2)\n",
    "            \n",
    "            training_cost = self.cost_function(self.train_l.T, y_hat, total_train_samples)\n",
    "            testing_cost = self.cost_function(self.test_l.T, y_pred, total_test_samples)\n",
    "            \n",
    "            train_costs.append(training_cost)    \n",
    "            test_costs.append(testing_cost)\n",
    "            epochs_list.append(epoch)\n",
    "            \n",
    "            self.weights_layer1, self.weights_layer2, self.biases_layer1, self.biases_layer2 = self.backward_pass(y_hat, weighted_sums_layer1)\n",
    "        \n",
    "        print(f\"Final Training Cost at Epoch [{epoch}]: {training_cost}\")\n",
    "        print(f\"Final Testing Cost at Epoch [{epoch}]: {testing_cost}\")\n",
    "        plot_data(train_costs, test_costs, epochs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab242d50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T05:21:44.634744Z",
     "iopub.status.busy": "2022-10-29T05:21:44.633706Z",
     "iopub.status.idle": "2022-10-29T05:42:44.126064Z",
     "shell.execute_reply": "2022-10-29T05:42:44.124607Z"
    },
    "papermill": {
     "duration": 1259.501704,
     "end_time": "2022-10-29T05:42:44.129036",
     "exception": false,
     "start_time": "2022-10-29T05:21:44.627332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetures Before One Hot Encoding \n",
      "        1        2       3   4   5          6  7  8  9          10\n",
      "1      619   France  Female  42   2          0  1  1  1  101348.88\n",
      "2      608    Spain  Female  41   1   83807.86  1  0  1  112542.58\n",
      "3      502   France  Female  42   8   159660.8  3  1  0  113931.57\n",
      "4      699   France  Female  39   1          0  2  0  0   93826.63\n",
      "5      850    Spain  Female  43   2  125510.82  1  1  1    79084.1\n",
      "...    ...      ...     ...  ..  ..        ... .. .. ..        ...\n",
      "9996   771   France    Male  39   5          0  2  1  0   96270.64\n",
      "9997   516   France    Male  35  10   57369.61  1  1  1  101699.77\n",
      "9998   709   France  Female  36   7          0  1  0  1   42085.58\n",
      "9999   772  Germany    Male  42   3   75075.31  2  1  0   92888.52\n",
      "10000  792   France  Female  28   4  130142.79  1  1  0   38190.78\n",
      "\n",
      "[10000 rows x 10 columns]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Labels \n",
      "1        1\n",
      "2        0\n",
      "3        1\n",
      "4        0\n",
      "5        0\n",
      "        ..\n",
      "9996     0\n",
      "9997     0\n",
      "9998     1\n",
      "9999     1\n",
      "10000    0\n",
      "Name: 11, Length: 10000, dtype: object\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Fetures After One Hot Encoding \n",
      "         1   4   5          6  7  8  9         10  France  Germany  Spain  \\\n",
      "1      619  42   2          0  1  1  1  101348.88       1        0      0   \n",
      "2      608  41   1   83807.86  1  0  1  112542.58       0        0      1   \n",
      "3      502  42   8   159660.8  3  1  0  113931.57       1        0      0   \n",
      "4      699  39   1          0  2  0  0   93826.63       1        0      0   \n",
      "5      850  43   2  125510.82  1  1  1    79084.1       0        0      1   \n",
      "...    ...  ..  ..        ... .. .. ..        ...     ...      ...    ...   \n",
      "9996   771  39   5          0  2  1  0   96270.64       1        0      0   \n",
      "9997   516  35  10   57369.61  1  1  1  101699.77       1        0      0   \n",
      "9998   709  36   7          0  1  0  1   42085.58       1        0      0   \n",
      "9999   772  42   3   75075.31  2  1  0   92888.52       0        1      0   \n",
      "10000  792  28   4  130142.79  1  1  0   38190.78       1        0      0   \n",
      "\n",
      "       Female  Male  \n",
      "1           1     0  \n",
      "2           1     0  \n",
      "3           1     0  \n",
      "4           1     0  \n",
      "5           1     0  \n",
      "...       ...   ...  \n",
      "9996        0     1  \n",
      "9997        0     1  \n",
      "9998        1     0  \n",
      "9999        0     1  \n",
      "10000       1     0  \n",
      "\n",
      "[10000 rows x 13 columns]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Training Features \n",
      "          1     4     5          6    7    8    9         10  France  Germany  \\\n",
      "0     732.0  36.0   7.0  126195.81  1.0  1.0  1.0  133172.48     1.0      0.0   \n",
      "1     429.0  39.0   6.0   48023.83  1.0  1.0  0.0   74870.99     1.0      0.0   \n",
      "2     743.0  45.0  10.0  144677.19  3.0  1.0  0.0   22512.44     0.0      1.0   \n",
      "3     737.0  45.0  10.0       0.00  2.0  1.0  0.0    1364.54     1.0      0.0   \n",
      "4     648.0  36.0   8.0  146943.38  2.0  1.0  1.0  130041.45     0.0      0.0   \n",
      "...     ...   ...   ...        ...  ...  ...  ...        ...     ...      ...   \n",
      "7995  671.0  45.0   6.0   99564.22  1.0  1.0  1.0  108872.45     0.0      1.0   \n",
      "7996  587.0  42.0   5.0  120233.83  1.0  1.0  0.0  194890.33     0.0      0.0   \n",
      "7997  711.0  45.0   1.0   97486.15  2.0  1.0  0.0   50610.62     0.0      1.0   \n",
      "7998  652.0  47.0   0.0  126597.89  2.0  1.0  1.0   38798.79     0.0      1.0   \n",
      "7999  656.0  41.0   2.0       0.00  2.0  1.0  0.0  158973.77     1.0      0.0   \n",
      "\n",
      "      Spain  Female  Male  \n",
      "0       0.0     0.0   1.0  \n",
      "1       0.0     1.0   0.0  \n",
      "2       0.0     0.0   1.0  \n",
      "3       0.0     0.0   1.0  \n",
      "4       1.0     0.0   1.0  \n",
      "...     ...     ...   ...  \n",
      "7995    0.0     0.0   1.0  \n",
      "7996    1.0     0.0   1.0  \n",
      "7997    0.0     1.0   0.0  \n",
      "7998    0.0     1.0   0.0  \n",
      "7999    0.0     0.0   1.0  \n",
      "\n",
      "[8000 rows x 13 columns]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Testing Features \n",
      "          1     4    5          6    7    8    9         10  France  Germany  \\\n",
      "0     713.0  26.0  4.0  122857.46  2.0  1.0  0.0  144682.17     0.0      0.0   \n",
      "1     506.0  32.0  8.0       0.00  2.0  0.0  1.0  182692.80     0.0      0.0   \n",
      "2     850.0  35.0  9.0       0.00  2.0  0.0  0.0   25329.48     1.0      0.0   \n",
      "3     535.0  40.0  7.0  111756.50  1.0  1.0  0.0    8128.32     0.0      1.0   \n",
      "4     562.0  36.0  6.0       0.00  2.0  1.0  0.0   32845.32     1.0      0.0   \n",
      "...     ...   ...  ...        ...  ...  ...  ...        ...     ...      ...   \n",
      "1995  804.0  24.0  3.0       0.00  2.0  1.0  0.0  173195.33     1.0      0.0   \n",
      "1996  755.0  43.0  6.0  165048.50  3.0  1.0  0.0   16929.41     0.0      1.0   \n",
      "1997  546.0  42.0  9.0   86351.85  2.0  1.0  0.0   57380.13     0.0      1.0   \n",
      "1998  629.0  40.0  6.0       0.00  2.0  1.0  1.0  139356.30     1.0      0.0   \n",
      "1999  714.0  42.0  2.0  177640.09  1.0  0.0  1.0   47166.55     0.0      1.0   \n",
      "\n",
      "      Spain  Female  Male  \n",
      "0       1.0     1.0   0.0  \n",
      "1       1.0     0.0   1.0  \n",
      "2       0.0     1.0   0.0  \n",
      "3       0.0     0.0   1.0  \n",
      "4       0.0     0.0   1.0  \n",
      "...     ...     ...   ...  \n",
      "1995    0.0     0.0   1.0  \n",
      "1996    0.0     0.0   1.0  \n",
      "1997    0.0     1.0   0.0  \n",
      "1998    0.0     1.0   0.0  \n",
      "1999    0.0     0.0   1.0  \n",
      "\n",
      "[2000 rows x 13 columns]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Training Labels \n",
      "0       0.0\n",
      "1       0.0\n",
      "2       1.0\n",
      "3       0.0\n",
      "4       0.0\n",
      "       ... \n",
      "7995    1.0\n",
      "7996    0.0\n",
      "7997    0.0\n",
      "7998    1.0\n",
      "7999    0.0\n",
      "Name: 11, Length: 8000, dtype: float64\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Testing Labels \n",
      "0       1.0\n",
      "1       0.0\n",
      "2       0.0\n",
      "3       1.0\n",
      "4       0.0\n",
      "       ... \n",
      "1995    0.0\n",
      "1996    1.0\n",
      "1997    0.0\n",
      "1998    0.0\n",
      "1999    0.0\n",
      "Name: 11, Length: 2000, dtype: float64\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Training Features After Min-Max Normalization \n",
      "          1         4    5         6         7    8    9        10  France  \\\n",
      "0     0.764  0.243243  0.7  0.502976  0.000000  1.0  1.0  0.665868     1.0   \n",
      "1     0.158  0.283784  0.6  0.191408  0.000000  1.0  0.0  0.374333     1.0   \n",
      "2     0.786  0.364865  1.0  0.576637  0.666667  1.0  0.0  0.112515     0.0   \n",
      "3     0.774  0.364865  1.0  0.000000  0.333333  1.0  0.0  0.006765     1.0   \n",
      "4     0.596  0.243243  0.8  0.585670  0.333333  1.0  1.0  0.650211     0.0   \n",
      "...     ...       ...  ...       ...       ...  ...  ...       ...     ...   \n",
      "7995  0.642  0.364865  0.6  0.396831  0.000000  1.0  1.0  0.544356     0.0   \n",
      "7996  0.474  0.324324  0.5  0.479214  0.000000  1.0  0.0  0.974487     0.0   \n",
      "7997  0.722  0.364865  0.1  0.388549  0.333333  1.0  0.0  0.253019     0.0   \n",
      "7998  0.604  0.391892  0.0  0.504579  0.333333  1.0  1.0  0.193955     0.0   \n",
      "7999  0.612  0.310811  0.2  0.000000  0.333333  1.0  0.0  0.794887     1.0   \n",
      "\n",
      "      Germany  Spain  Female  Male  \n",
      "0         0.0    0.0     0.0   1.0  \n",
      "1         0.0    0.0     1.0   0.0  \n",
      "2         1.0    0.0     0.0   1.0  \n",
      "3         0.0    0.0     0.0   1.0  \n",
      "4         0.0    1.0     0.0   1.0  \n",
      "...       ...    ...     ...   ...  \n",
      "7995      1.0    0.0     0.0   1.0  \n",
      "7996      0.0    1.0     0.0   1.0  \n",
      "7997      1.0    0.0     1.0   0.0  \n",
      "7998      1.0    0.0     1.0   0.0  \n",
      "7999      0.0    0.0     0.0   1.0  \n",
      "\n",
      "[8000 rows x 13 columns]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Testing Features After Min-Max Normalization \n",
      "             1         4    5         6         7    8    9        10  France  \\\n",
      "0     0.712788  0.108108  0.4  0.578659  0.333333  1.0  0.0  0.723318     0.0   \n",
      "1     0.278826  0.189189  0.8  0.000000  0.333333  0.0  1.0  0.913536     0.0   \n",
      "2     1.000000  0.229730  0.9  0.000000  0.333333  0.0  0.0  0.126039     1.0   \n",
      "3     0.339623  0.297297  0.7  0.526374  0.000000  1.0  0.0  0.039959     0.0   \n",
      "4     0.396226  0.243243  0.6  0.000000  0.333333  1.0  0.0  0.163651     1.0   \n",
      "...        ...       ...  ...       ...       ...  ...  ...       ...     ...   \n",
      "1995  0.903564  0.081081  0.3  0.000000  0.333333  1.0  0.0  0.866007     1.0   \n",
      "1996  0.800839  0.337838  0.6  0.777379  0.666667  1.0  0.0  0.084003     0.0   \n",
      "1997  0.362683  0.324324  0.9  0.406718  0.333333  1.0  0.0  0.286431     0.0   \n",
      "1998  0.536688  0.297297  0.6  0.000000  0.333333  1.0  1.0  0.696666     1.0   \n",
      "1999  0.714885  0.324324  0.2  0.836686  0.000000  0.0  1.0  0.235319     0.0   \n",
      "\n",
      "      Germany  Spain  Female  Male  \n",
      "0         0.0    1.0     1.0   0.0  \n",
      "1         0.0    1.0     0.0   1.0  \n",
      "2         0.0    0.0     1.0   0.0  \n",
      "3         1.0    0.0     0.0   1.0  \n",
      "4         0.0    0.0     0.0   1.0  \n",
      "...       ...    ...     ...   ...  \n",
      "1995      0.0    0.0     0.0   1.0  \n",
      "1996      1.0    0.0     0.0   1.0  \n",
      "1997      1.0    0.0     1.0   0.0  \n",
      "1998      0.0    0.0     1.0   0.0  \n",
      "1999      1.0    0.0     0.0   1.0  \n",
      "\n",
      "[2000 rows x 13 columns]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 20001/20001 [20:58<00:00, 15.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Cost at Epoch [20000]: 0.5064379912962205\n",
      "Final Testing Cost at Epoch [20000]: 0.5020293673886298\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 20000\n",
    "learning_rate = 0.005\n",
    "hidden_nodes = 3\n",
    "\n",
    "network = Neural_Network(epochs, learning_rate, hidden_nodes)\n",
    "network.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1271.377147,
   "end_time": "2022-10-29T05:42:45.675647",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-10-29T05:21:34.298500",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
