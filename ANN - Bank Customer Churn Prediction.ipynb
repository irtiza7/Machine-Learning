{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55563c65",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-10-25T10:57:35.159377Z",
     "iopub.status.busy": "2022-10-25T10:57:35.158851Z",
     "iopub.status.idle": "2022-10-25T10:57:36.366871Z",
     "shell.execute_reply": "2022-10-25T10:57:36.365855Z"
    },
    "papermill": {
     "duration": 1.216517,
     "end_time": "2022-10-25T10:57:36.369954",
     "exception": false,
     "start_time": "2022-10-25T10:57:35.153437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60b8d1ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-25T10:57:36.377373Z",
     "iopub.status.busy": "2022-10-25T10:57:36.376956Z",
     "iopub.status.idle": "2022-10-25T10:57:36.391779Z",
     "shell.execute_reply": "2022-10-25T10:57:36.390650Z"
    },
    "papermill": {
     "duration": 0.021645,
     "end_time": "2022-10-25T10:57:36.394648",
     "exception": false,
     "start_time": "2022-10-25T10:57:36.373003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def load_data(self):\n",
    "        path = r\"../input/datasets-for-regression/Bank_Customer_Churn_Prediction/Bank_Customer_Churn_Prediction.csv\"\n",
    "    \n",
    "        df = pd.read_csv(path, header=None, delimiter=\",\")\n",
    "        df = df.drop(0, axis = 1)\n",
    "        features = df.iloc[1:, 0:10]\n",
    "        labels = df.iloc[1:, -1]\n",
    "        return (features, labels)\n",
    "\n",
    "    def one_hot_encode(self, features):\n",
    "        encoded_country = pd.get_dummies(features[2])\n",
    "        encoded_gender = pd.get_dummies(features[3])\n",
    "    \n",
    "        merged_columns = pd.concat([encoded_country, encoded_gender], axis = \"columns\")\n",
    "        features = pd.concat([features, merged_columns], axis = \"columns\")\n",
    "        features = features.drop([2, 3], axis = \"columns\")\n",
    "        return features\n",
    "    \n",
    "    def split_data(self, features, labels):\n",
    "        total_samples = features.shape[0]\n",
    "        feature_columns = features.columns.values.tolist()\n",
    "        test_split_size = int(np.ceil((20 / 100) * total_samples))\n",
    "    \n",
    "        train_x, test_x, train_y, test_y = train_test_split(features, labels, test_size = test_split_size)\n",
    "\n",
    "        train_x = train_x.reset_index(drop = True)\n",
    "        test_x = test_x.reset_index(drop = True)\n",
    "        train_y = train_y.reset_index(drop = True)\n",
    "        test_y = test_y.reset_index(drop = True)\n",
    "    \n",
    "        train_y = train_y.astype(float)\n",
    "        test_y = test_y.astype(float)\n",
    "\n",
    "        for column in feature_columns:\n",
    "            train_x[column] = train_x[column].astype(float)\n",
    "            test_x[column] = test_x[column].astype(float)\n",
    "\n",
    "        return (train_x, test_x, train_y, test_y)\n",
    "    \n",
    "    def min_max_normalization(self, df):\n",
    "        normalized_df = (df - df.min()) / (df.max() - df.min())\n",
    "        return normalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52acb35d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-25T10:57:36.401611Z",
     "iopub.status.busy": "2022-10-25T10:57:36.401224Z",
     "iopub.status.idle": "2022-10-25T10:57:36.426676Z",
     "shell.execute_reply": "2022-10-25T10:57:36.425558Z"
    },
    "papermill": {
     "duration": 0.032115,
     "end_time": "2022-10-25T10:57:36.429393",
     "exception": false,
     "start_time": "2022-10-25T10:57:36.397278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Neural_Network():\n",
    "    def __init__(self, epochs, lr, hidden_nodes):\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        \n",
    "        # Getting features and labels\n",
    "        dataset = Dataset()\n",
    "        self.features, self.labels = dataset.load_data()\n",
    "        print(f\"Fetures Before One Hot Encoding \\n{self.features}\\n\" + \"-\" * 150, \"\\n\")\n",
    "        print(f\"Labels \\n{self.labels}\\n\" + \"-\" * 150, \"\\n\")\n",
    "        \n",
    "        # Applying One Hot Encoding\n",
    "        self.features = dataset.one_hot_encode(self.features)\n",
    "        print(f\"Fetures After One Hot Encoding \\n{self.features}\\n\" + \"-\" * 150, \"\\n\")\n",
    "        \n",
    "        # Spilitting data into training and testing subsets\n",
    "        self.train_f, self.test_f, self.train_l, self.test_l = dataset.split_data(self.features, self.labels)\n",
    "        print(f\"Training Features \\n{self.train_f}\\n\" + \"-\" * 150, \"\\n\")\n",
    "        print(f\"Testing Features \\n{self.test_f}\\n\" + \"-\" * 150, \"\\n\")\n",
    "        print(f\"Training Labels \\n{self.train_l}\\n\" + \"-\" * 150, \"\\n\")\n",
    "        print(f\"Testing Labels \\n{self.test_l}\\n\" + \"-\" * 150, \"\\n\")\n",
    "        \n",
    "        # Normalizing features\n",
    "        self.train_f = dataset.min_max_normalization(self.train_f)\n",
    "        self.test_f = dataset.min_max_normalization(self.test_f)\n",
    "        print(f\"Training Features After Min-Max Normalization \\n{self.train_f}\\n\" + \"-\" * 150, \"\\n\")\n",
    "        print(f\"Testing Features After Min-Max Normalization \\n{self.test_f}\\n\" + \"-\" * 150, \"\\n\")\n",
    "        \n",
    "        # Initializing weights and biases for both layers\n",
    "        self.weights_layer1, self.weights_layer2, self.biases_layer1, self.biases_layer2 = self.init_parameters(13, self.hidden_nodes, 1)\n",
    "        \n",
    "    \n",
    "    def forward_pass(self, inputs, weights_layer1, weights_layer2, biases_layer1, biases_layer2):\n",
    "        # Weighted sum for layer 1\n",
    "        weighted_sums_layer1 = self.calculate_weighted_sum(weights_layer1, input_features)\n",
    "        weighted_sums_layer1 = self.add_biases(weighted_sums_layer1, biases_layer1)\n",
    "        \n",
    "        # Applying Relu\n",
    "        for index in range(self.hidden_nodes):\n",
    "            weighted_sum_layer1[index] = self.relu(weighted_sum_layer1[index])\n",
    "        \n",
    "        # Weighted sum for layer 2\n",
    "        weighted_sums_layer2 = self.calculate_weighted_sum(weights_layer2, weighted_sums_layer1)\n",
    "        weighted_sums_layer2 = self.add_biases(weighted_sums_layer2, biases_layer2)\n",
    "        \n",
    "        # Applying Sigmoid\n",
    "        y_hat = self.sigmoid(weighted_sums_layer2)\n",
    "        return y_hat, weighted_sums_layer1\n",
    "    \n",
    "    def calculate_weighted_sum(weights, inputs):\n",
    "        weighted_sum = np.dot(weights, inputs)\n",
    "        return weighted_sum\n",
    "\n",
    "    def add_biases(weighted_sum, biases):\n",
    "        return np.add(weighted_sum, biases)\n",
    "    \n",
    "    def backward_pass(self, y_hat, weighted_sums_layer1):\n",
    "        # Calculate gradient of output node\n",
    "        error_O = y_hat * (1 - y_hat) * (self.train_l - y_hat)\n",
    "        \n",
    "        # Calculate gradient of hidden nodes\n",
    "        t1 = np.product(self.weights_layer2, error_O)\n",
    "        t2 = np.product(weighted_sums_layer1, (1 - weighted_sums_layer1))\n",
    "        errors_H = t1 * t2\n",
    "        \n",
    "        # Calculating new parameters for layer 2\n",
    "        weights_layer2 = np.sum(self.weights_layer2, np.product(self.lr, np.product(error_O, weighted_sums_layer1)))\n",
    "        biases_layer2 = np.sum(self.biases_layer2, np.product(self.lr, error_O))\n",
    "        \n",
    "        # Calculating new parameters for layer 1\n",
    "        weights_layer1 = np.sum(self.weights_layer1, np.product(self.lr, np.product(errors_H, self.train_f)))\n",
    "        biases_layer1 = np.sum(self.biases_layer1, np.product(self.lr, errors_H))\n",
    "        \n",
    "        return (weights_layer1, weights_layer2, biases_layer1, biases_layer2)\n",
    "    \n",
    "    \n",
    "    def fit(self):\n",
    "        for epoch in range(self.epochs):\n",
    "            y_hat, weighted_sums_layer1 = self.forward_pass(self.train_f, self.weights_layer1, self.weights_layer2, self.biases_layer1, self.biases_layer2)\n",
    "            \n",
    "            total_train_samples = self.train_f.shape[0]\n",
    "            training_cost = self.cost_function(self.train_l, y_hat, total_train_samples)\n",
    "            print(f\"Training Cost at Epoch [{epoch + 1}] is {training_cost}\")\n",
    "            \n",
    "            self.weights_layer1, self.weights_layer2, self.biases_layer1, self.biases_layer2 = self.backward_pass(y_hat, weighted_sums_layer1)\n",
    "    \n",
    "    def init_parameters(self, input_features, hidden_nodes, output_nodes):\n",
    "        num_weights_l1 = input_features * hidden_nodes\n",
    "        num_weights_l2 = hidden_nodes * output_nodes\n",
    "        num_biases_l1 = hidden_nodes\n",
    "        num_biases_l2 = output_nodes\n",
    "        \n",
    "        weights_layer1 = []\n",
    "        weights_layer2 = []\n",
    "        biases_layer1 = []\n",
    "        biases_layer2 = []\n",
    "        \n",
    "#         temp.append(round(random.uniform(-0.5, 0.5), 1))\n",
    "        \n",
    "        return (weights_layer1, weights_layer2, biases_layer1, biases_layer2)\n",
    "    \n",
    "    \n",
    "    def cost_function(self, y, y_hat, total_samples):\n",
    "        cost = (-1 / total_samples) * np.sum(y * np.log(0.0001 + y_hat) + (1 - y) * np.log(0.0001 + 1 - y_hat))\n",
    "        return cost\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        z = 1 / (1 + np.exp(-z))\n",
    "        return z\n",
    "\n",
    "    def relu(self, z):\n",
    "        return np.maximum(z, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d73ef64e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-25T10:57:36.436128Z",
     "iopub.status.busy": "2022-10-25T10:57:36.435724Z",
     "iopub.status.idle": "2022-10-25T10:57:36.624347Z",
     "shell.execute_reply": "2022-10-25T10:57:36.622935Z"
    },
    "papermill": {
     "duration": 0.197232,
     "end_time": "2022-10-25T10:57:36.629189",
     "exception": false,
     "start_time": "2022-10-25T10:57:36.431957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetures Before One Hot Encoding \n",
      "        1        2       3   4   5          6  7  8  9          10\n",
      "1      619   France  Female  42   2          0  1  1  1  101348.88\n",
      "2      608    Spain  Female  41   1   83807.86  1  0  1  112542.58\n",
      "3      502   France  Female  42   8   159660.8  3  1  0  113931.57\n",
      "4      699   France  Female  39   1          0  2  0  0   93826.63\n",
      "5      850    Spain  Female  43   2  125510.82  1  1  1    79084.1\n",
      "...    ...      ...     ...  ..  ..        ... .. .. ..        ...\n",
      "9996   771   France    Male  39   5          0  2  1  0   96270.64\n",
      "9997   516   France    Male  35  10   57369.61  1  1  1  101699.77\n",
      "9998   709   France  Female  36   7          0  1  0  1   42085.58\n",
      "9999   772  Germany    Male  42   3   75075.31  2  1  0   92888.52\n",
      "10000  792   France  Female  28   4  130142.79  1  1  0   38190.78\n",
      "\n",
      "[10000 rows x 10 columns]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Labels \n",
      "1        1\n",
      "2        0\n",
      "3        1\n",
      "4        0\n",
      "5        0\n",
      "        ..\n",
      "9996     0\n",
      "9997     0\n",
      "9998     1\n",
      "9999     1\n",
      "10000    0\n",
      "Name: 11, Length: 10000, dtype: object\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Fetures After One Hot Encoding \n",
      "         1   4   5          6  7  8  9         10  France  Germany  Spain  \\\n",
      "1      619  42   2          0  1  1  1  101348.88       1        0      0   \n",
      "2      608  41   1   83807.86  1  0  1  112542.58       0        0      1   \n",
      "3      502  42   8   159660.8  3  1  0  113931.57       1        0      0   \n",
      "4      699  39   1          0  2  0  0   93826.63       1        0      0   \n",
      "5      850  43   2  125510.82  1  1  1    79084.1       0        0      1   \n",
      "...    ...  ..  ..        ... .. .. ..        ...     ...      ...    ...   \n",
      "9996   771  39   5          0  2  1  0   96270.64       1        0      0   \n",
      "9997   516  35  10   57369.61  1  1  1  101699.77       1        0      0   \n",
      "9998   709  36   7          0  1  0  1   42085.58       1        0      0   \n",
      "9999   772  42   3   75075.31  2  1  0   92888.52       0        1      0   \n",
      "10000  792  28   4  130142.79  1  1  0   38190.78       1        0      0   \n",
      "\n",
      "       Female  Male  \n",
      "1           1     0  \n",
      "2           1     0  \n",
      "3           1     0  \n",
      "4           1     0  \n",
      "5           1     0  \n",
      "...       ...   ...  \n",
      "9996        0     1  \n",
      "9997        0     1  \n",
      "9998        1     0  \n",
      "9999        0     1  \n",
      "10000       1     0  \n",
      "\n",
      "[10000 rows x 13 columns]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Training Features \n",
      "          1     4     5          6    7    8    9         10  France  Germany  \\\n",
      "0     782.0  36.0   5.0   81210.72  2.0  0.0  1.0  108003.38     1.0      0.0   \n",
      "1     652.0  38.0   1.0  103895.31  1.0  0.0  1.0  159649.44     0.0      0.0   \n",
      "2     754.0  38.0   2.0       0.00  2.0  1.0  0.0  180698.32     1.0      0.0   \n",
      "3     623.0  40.0   7.0       0.00  1.0  1.0  1.0   25904.12     0.0      0.0   \n",
      "4     568.0  33.0   7.0       0.00  2.0  1.0  0.0  143450.61     1.0      0.0   \n",
      "...     ...   ...   ...        ...  ...  ...  ...        ...     ...      ...   \n",
      "7995  646.0  18.0  10.0       0.00  2.0  0.0  1.0   52795.15     1.0      0.0   \n",
      "7996  539.0  38.0   5.0       0.00  2.0  1.0  0.0   47388.41     1.0      0.0   \n",
      "7997  590.0  38.0   9.0       0.00  2.0  1.0  1.0  148750.16     0.0      0.0   \n",
      "7998  605.0  41.0  10.0       0.00  2.0  0.0  1.0   97213.09     1.0      0.0   \n",
      "7999  439.0  28.0   7.0  110976.23  2.0  1.0  0.0  138526.96     1.0      0.0   \n",
      "\n",
      "      Spain  Female  Male  \n",
      "0       0.0     0.0   1.0  \n",
      "1       1.0     1.0   0.0  \n",
      "2       0.0     0.0   1.0  \n",
      "3       1.0     1.0   0.0  \n",
      "4       0.0     0.0   1.0  \n",
      "...     ...     ...   ...  \n",
      "7995    0.0     0.0   1.0  \n",
      "7996    0.0     0.0   1.0  \n",
      "7997    1.0     1.0   0.0  \n",
      "7998    0.0     0.0   1.0  \n",
      "7999    0.0     0.0   1.0  \n",
      "\n",
      "[8000 rows x 13 columns]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Testing Features \n",
      "          1     4    5          6    7    8    9         10  France  Germany  \\\n",
      "0     559.0  34.0  2.0  137390.11  2.0  1.0  0.0    9677.00     1.0      0.0   \n",
      "1     591.0  28.0  5.0       0.00  2.0  1.0  1.0   48606.92     1.0      0.0   \n",
      "2     616.0  31.0  3.0   94263.91  2.0  1.0  0.0  168895.06     1.0      0.0   \n",
      "3     747.0  37.0  9.0  135776.36  3.0  1.0  0.0   85470.45     0.0      1.0   \n",
      "4     576.0  52.0  2.0  100549.43  2.0  1.0  1.0   16644.16     0.0      0.0   \n",
      "...     ...   ...  ...        ...  ...  ...  ...        ...     ...      ...   \n",
      "1995  749.0  66.0  6.0  182532.23  2.0  1.0  1.0  195429.92     0.0      1.0   \n",
      "1996  585.0  38.0  5.0       0.00  1.0  1.0  1.0   87363.56     1.0      0.0   \n",
      "1997  628.0  46.0  1.0   46870.43  4.0  1.0  0.0   31272.14     1.0      0.0   \n",
      "1998  553.0  47.0  3.0  116528.15  1.0  0.0  0.0  145704.19     0.0      0.0   \n",
      "1999  748.0  40.0  3.0  103499.09  2.0  0.0  0.0   38153.19     0.0      1.0   \n",
      "\n",
      "      Spain  Female  Male  \n",
      "0       0.0     0.0   1.0  \n",
      "1       0.0     0.0   1.0  \n",
      "2       0.0     0.0   1.0  \n",
      "3       0.0     0.0   1.0  \n",
      "4       1.0     0.0   1.0  \n",
      "...     ...     ...   ...  \n",
      "1995    0.0     0.0   1.0  \n",
      "1996    0.0     1.0   0.0  \n",
      "1997    0.0     1.0   0.0  \n",
      "1998    1.0     0.0   1.0  \n",
      "1999    0.0     1.0   0.0  \n",
      "\n",
      "[2000 rows x 13 columns]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Training Labels \n",
      "0       0.0\n",
      "1       0.0\n",
      "2       0.0\n",
      "3       0.0\n",
      "4       0.0\n",
      "       ... \n",
      "7995    0.0\n",
      "7996    0.0\n",
      "7997    0.0\n",
      "7998    0.0\n",
      "7999    0.0\n",
      "Name: 11, Length: 8000, dtype: float64\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Testing Labels \n",
      "0       0.0\n",
      "1       0.0\n",
      "2       0.0\n",
      "3       1.0\n",
      "4       0.0\n",
      "       ... \n",
      "1995    0.0\n",
      "1996    0.0\n",
      "1997    1.0\n",
      "1998    1.0\n",
      "1999    0.0\n",
      "Name: 11, Length: 2000, dtype: float64\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Training Features After Min-Max Normalization \n",
      "          1         4    5         6         7    8    9        10  France  \\\n",
      "0     0.864  0.243243  0.5  0.323680  0.333333  0.0  1.0  0.540011     1.0   \n",
      "1     0.604  0.270270  0.1  0.414094  0.000000  0.0  1.0  0.798266     0.0   \n",
      "2     0.808  0.270270  0.2  0.000000  0.333333  1.0  0.0  0.903520     1.0   \n",
      "3     0.546  0.297297  0.7  0.000000  0.000000  1.0  1.0  0.129475     0.0   \n",
      "4     0.436  0.202703  0.7  0.000000  0.333333  1.0  0.0  0.717264     1.0   \n",
      "...     ...       ...  ...       ...       ...  ...  ...       ...     ...   \n",
      "7995  0.592  0.000000  1.0  0.000000  0.333333  0.0  1.0  0.263943     1.0   \n",
      "7996  0.378  0.270270  0.5  0.000000  0.333333  1.0  0.0  0.236907     1.0   \n",
      "7997  0.480  0.270270  0.9  0.000000  0.333333  1.0  1.0  0.743764     0.0   \n",
      "7998  0.510  0.310811  1.0  0.000000  0.333333  0.0  1.0  0.486054     1.0   \n",
      "7999  0.178  0.135135  0.7  0.442316  0.333333  1.0  0.0  0.692643     1.0   \n",
      "\n",
      "      Germany  Spain  Female  Male  \n",
      "0         0.0    0.0     0.0   1.0  \n",
      "1         0.0    1.0     1.0   0.0  \n",
      "2         0.0    0.0     0.0   1.0  \n",
      "3         0.0    1.0     1.0   0.0  \n",
      "4         0.0    0.0     0.0   1.0  \n",
      "...       ...    ...     ...   ...  \n",
      "7995      0.0    0.0     0.0   1.0  \n",
      "7996      0.0    0.0     0.0   1.0  \n",
      "7997      0.0    1.0     1.0   0.0  \n",
      "7998      0.0    0.0     0.0   1.0  \n",
      "7999      0.0    0.0     0.0   1.0  \n",
      "\n",
      "[8000 rows x 13 columns]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------ \n",
      "\n",
      "Testing Features After Min-Max Normalization \n",
      "          1         4    5         6         7    8    9        10  France  \\\n",
      "0     0.418  0.216216  0.2  0.576331  0.333333  1.0  0.0  0.047275     1.0   \n",
      "1     0.482  0.135135  0.5  0.000000  0.333333  1.0  1.0  0.242225     1.0   \n",
      "2     0.532  0.175676  0.3  0.395423  0.333333  1.0  0.0  0.844591     1.0   \n",
      "3     0.794  0.256757  0.9  0.569561  0.666667  1.0  0.0  0.426826     0.0   \n",
      "4     0.452  0.459459  0.2  0.421790  0.333333  1.0  1.0  0.082165     0.0   \n",
      "...     ...       ...  ...       ...       ...  ...  ...       ...     ...   \n",
      "1995  0.798  0.648649  0.6  0.765695  0.333333  1.0  1.0  0.977469     0.0   \n",
      "1996  0.470  0.270270  0.5  0.000000  0.000000  1.0  1.0  0.436306     1.0   \n",
      "1997  0.556  0.378378  0.1  0.196614  1.000000  1.0  0.0  0.155417     1.0   \n",
      "1998  0.406  0.391892  0.3  0.488818  0.000000  0.0  0.0  0.728458     0.0   \n",
      "1999  0.796  0.297297  0.3  0.434163  0.333333  0.0  0.0  0.189875     0.0   \n",
      "\n",
      "      Germany  Spain  Female  Male  \n",
      "0         0.0    0.0     0.0   1.0  \n",
      "1         0.0    0.0     0.0   1.0  \n",
      "2         0.0    0.0     0.0   1.0  \n",
      "3         1.0    0.0     0.0   1.0  \n",
      "4         0.0    1.0     0.0   1.0  \n",
      "...       ...    ...     ...   ...  \n",
      "1995      1.0    0.0     0.0   1.0  \n",
      "1996      0.0    0.0     1.0   0.0  \n",
      "1997      0.0    0.0     1.0   0.0  \n",
      "1998      0.0    1.0     0.0   1.0  \n",
      "1999      1.0    0.0     1.0   0.0  \n",
      "\n",
      "[2000 rows x 13 columns]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# epochs = int(input(\"Epochs: \"))\n",
    "# hidden_nodes = int(input(\"Hidden Units: \"))\n",
    "# lr = float(input(\"Learning Rate: \"))\n",
    "network = Neural_Network(10, 0.0001, 3)\n",
    "# network.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba4a3323",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-25T10:57:36.637169Z",
     "iopub.status.busy": "2022-10-25T10:57:36.636224Z",
     "iopub.status.idle": "2022-10-25T10:57:36.640147Z",
     "shell.execute_reply": "2022-10-25T10:57:36.639403Z"
    },
    "papermill": {
     "duration": 0.010182,
     "end_time": "2022-10-25T10:57:36.642349",
     "exception": false,
     "start_time": "2022-10-25T10:57:36.632167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# network_weights, network_biases = init_parameters(13, num_hidden_units, 1)\n",
    "# print(f\"Network Weights for Both Layers \\n{network_weights}\\n\" + \"-\" * 150, \"\\n\" + f\"Network Biases for Both Layers \\n{network_biases}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13.18463,
   "end_time": "2022-10-25T10:57:39.663739",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-10-25T10:57:26.479109",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
